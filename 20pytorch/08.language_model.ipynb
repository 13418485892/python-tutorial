{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## build language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import numpy as np\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(lower=True)\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(path='.',\n",
    "                                                                     train='./data/nietzsche.txt',\n",
    "                                                                     validation='./data/nietzsche.txt',\n",
    "                                                                     test='./data/nietzsche.txt',\n",
    "                                                                     text_field=TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<eos>', 'the', 'of', 'and', 'to', 'in', 'a', 'is']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1314"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi[\"mother\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"gpu\" if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits((train,val,test),\n",
    "                                                                     batch_size=BATCH_SIZE,\n",
    "                                                                     device=device,\n",
    "                                                                     bptt_len=50,\n",
    "                                                                     repeat=False,\n",
    "                                                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14238,     2,     2,     2,   760,    10,   185,     9,     8, 17550,\n        16480,     9,    38,    16,  2281,     2,    13, 16272,    10,    20,\n          690,     7,    39,   106,    11,    31,    26,    54,     2,  4254,\n           26,  4399,     6,   252, 17555,     3,   654,     2,  1615,     5,\n         1230, 11670,    17,    14,    31,    26,   769,  3243,     2,    29])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface <eos> <eos> <eos> supposing that truth is a woman--what then? is there not ground <eos> for suspecting that all philosophers, in so far as they have been <eos> dogmatists, have failed to understand women--that the terrible <eos> seriousness and clumsy importunity with which they have usually paid <eos> their\n\n<eos> <eos> <eos> supposing that truth is a woman--what then? is there not ground <eos> for suspecting that all philosophers, in so far as they have been <eos> dogmatists, have failed to understand women--that the terrible <eos> seriousness and clumsy importunity with which they have usually paid <eos> their addresses\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(TEXT.vocab.itos[i] for i in batch.text[:, 0].data.cpu()))\n",
    "print()\n",
    "print(\" \".join(TEXT.vocab.itos[i] for i in batch.target[:, 0].data.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}